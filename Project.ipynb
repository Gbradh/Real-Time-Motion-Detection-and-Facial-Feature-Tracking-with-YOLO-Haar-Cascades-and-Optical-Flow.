{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0af96c8",
   "metadata": {},
   "source": [
    "Real-Time Motion Detection and Facial Feature Tracking with YOLO, Haar Cascades, and Optical Flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a98979c2-64df-4a44-bb1c-feb83cd07f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7782003b-4ad9-43be-8e4e-f9333493cb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DataFrame with start and end time\n",
    "df = pd.DataFrame(columns=[\"Start\", \"End\"])\n",
    "motionImage = []\n",
    "time = []\n",
    "stillImage = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5c46055-fa96-45ae-8bd4-1401394b941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained Haar cascades for face, eyes, and spectacles detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "spectacles_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye_tree_eyeglasses.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac0833aa-ec52-44b8-b7de-cccad6347579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO model for object detection\n",
    "net = cv2.dnn.readNet(r'C:\\Users\\gurba\\Project\\Computer Vision Project\\yolov3.weights', r'C:\\Users\\gurba\\Project\\Computer Vision Project\\yolov3.cfg')\n",
    "with open(r'C:\\Users\\gurba\\Project\\Computer Vision Project\\coco.names', 'r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47518213-242d-433a-9e98-ab52e6d271d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for Lucas-Kanade optical flow\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eacb5fa6-21b6-4811-bbb0-e987472a24a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some random colors\n",
    "color = np.random.randint(0, 255, (100, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29962dfb-562e-4282-bc70-03af25525bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capturing video\n",
    "video = cv2.VideoCapture(0)\n",
    "video.set(cv2.CAP_PROP_FPS, 60)  # Set frame rate to 30 FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f7d3d4-56ab-4d38-a64f-29114702f7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background Subtractor\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8de6139-2d4a-4bac-b36c-7430537255db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take first frame and find corners in it\n",
    "ret, old_frame = video.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88382d7b-49a4-4deb-b771-37c5bd2ae808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "while True:\n",
    "    # Start reading image from video\n",
    "    check, frame = video.read()\n",
    "    motion = 0\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fgmask = fgbg.apply(frame)\n",
    "\n",
    "    # Convert color image to gray_scale image\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    if stillImage is None:\n",
    "        stillImage = gray\n",
    "        continue\n",
    "    # Still Image and current image.\n",
    "    diff_frame = cv2.absdiff(stillImage, gray)\n",
    "\n",
    "    # Change the image to white if static background and current frame is greater than 25.\n",
    "    thresh_frame = cv2.threshold(diff_frame, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh_frame = cv2.dilate(thresh_frame, None, iterations=2)\n",
    "    # Finding contour and hierarchy from a moving object.\n",
    "    contours, hierachy = cv2.findContours(thresh_frame.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) < 5000:  # Lower the threshold\n",
    "            continue\n",
    "        motion = 1\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "    # Append current status of motion\n",
    "    motionImage.append(motion)\n",
    "    motionImage = motionImage[-2:]\n",
    "    # Append Start time of motion\n",
    "    if len(motionImage) >= 2 and motionImage[-1] == 1 and motionImage[-2] == 0:\n",
    "        time.append(datetime.now())\n",
    "\n",
    "    # Append End time of motion\n",
    "    if len(motionImage) >= 2 and motionImage[-1] == 0 and motionImage[-2] == 1:\n",
    "        time.append(datetime.now())\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        roi_gray = gray[y:y + h, x:x + w]\n",
    "        roi_color = frame[y:y + h, x:x + w]\n",
    "\n",
    "        # Detect eyes\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "\n",
    "        # Detect spectacles\n",
    "        spectacles = spectacles_cascade.detectMultiScale(roi_gray)\n",
    "        for (sx, sy, sw, sh) in spectacles:\n",
    "            cv2.rectangle(roi_color, (sx, sy), (sx + sw, sy + sh), (0, 255, 255), 2)\n",
    "    \n",
    "    # Calculate optical flow\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Ensure p0 is not None and has valid points\n",
    "    if p0 is not None and len(p0) > 0:\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "        if p1 is not None:\n",
    "            good_new = p1[st == 1]\n",
    "            good_old = p0[st == 1]\n",
    "        else:\n",
    "            good_new = np.array([])\n",
    "            good_old = np.array([])\n",
    "    else:\n",
    "        good_new = np.array([])\n",
    "        good_old = np.array([])\n",
    "    \n",
    "    # Ensure good_new is a numpy array\n",
    "    good_new = np.array(good_new)\n",
    "    \n",
    "    # Now you can reshape it\n",
    "    p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "\n",
    "    # Draw the tracks\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel().astype(int)\n",
    "        c, d = old.ravel().astype(int)\n",
    "        mask = cv2.line(mask, (a, b), (c, d), color[i].tolist(), 2)\n",
    "        frame = cv2.circle(frame, (a, b), 5, color[i].tolist(), -1)\n",
    "\n",
    "    img = cv2.add(frame, mask)\n",
    "\n",
    "    # Display the frames\n",
    "    cv2.imshow(\"Frame\", img)\n",
    "    cv2.imshow(\"Foreground Mask\", fgmask)\n",
    "    cv2.imshow(\"Gray_Frame\", gray)\n",
    "    cv2.imshow(\"Threshold Frame\", thresh_frame)\n",
    "    cv2.imshow(\"Colored_Frame\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    # Press q to stop the process\n",
    "    if key == ord('q'):\n",
    "        if motion == 1:\n",
    "            time.append(datetime.now())\n",
    "        break\n",
    "\n",
    "    # Now update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate through the time list in pairs\n",
    "for i in range(0, len(time), 2):\n",
    "    if pd.notna(time[i]) and pd.notna(time[i + 1]):\n",
    "        # Append the pair to the data list\n",
    "        data.append({\"Start\": time[i], \"End\": time[i + 1]})\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "df = pd.DataFrame(data) \n",
    "\n",
    "# Print DataFrame to verify content\n",
    "print(df)\n",
    "\n",
    "# Creating a csv file in which time of movements will be saved\n",
    "try:\n",
    "    df.to_csv(\"FrameInMotion_time.csv\")\n",
    "    print(\"CSV file saved successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving CSV file: {e}\")\n",
    "\n",
    "video.release()\n",
    "\n",
    "# close window\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98910fd9-47f4-416f-9e79-ec4286dcf07d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b00629-77b9-4b7e-9733-8ec5be7183cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36fb488-94b3-4199-86c1-cd7e56c4a090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc869fdb-cd6f-466c-b1a5-e17c36a64d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34fb018-77b9-44fc-ae64-0390a6f996b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8606d4f5-e9d7-4d8e-a162-40436e875c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d881139-380d-4809-98fa-e268c4e9a4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b93e178-1e10-4629-9e48-a473b5fc8406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
